{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM85GdooFZl7waJERnGCxlP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buddhahacker/GreeterDistilled/blob/master/PDFSearchV17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhmtItOeDJti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GQ18Kd5F3uKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "22a3c0b4-bfd0-4c4d-80c0-6294c07d7da9"
      },
      "source": [
        "!pip install PyPDF2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61086 sha256=9b6454d00f04ac2c2c23be639fe5a3c5f647cd37e7279ab30c7a4e7e13a6976f\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t94J7vvZB0Jd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "e4ff58a0-177d-406f-df30-0a3d64c4dd93"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Spyder Editor\n",
        "\n",
        "This is a temporary script file.\n",
        "\"\"\"\n",
        "\n",
        "from os import chdir\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from time import time\n",
        "import PyPDF2\n",
        "import re\n",
        "import os\n",
        "\n",
        "\n",
        "import datetime as dt\n",
        "from multiprocessing import Process, current_process\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "####################################################################################\n",
        "############################### DIRECTORY LOCATION FOR FILES #######################\n",
        "####################################################################################\n",
        "\n",
        "# Steps:\n",
        "# 1 - Program base research directory below.\n",
        "# 2 - Enter the directory to be search in the DirectoryToSearch.rtf file under the directoryvar directory defined below.\n",
        "# 3 - Ensure that directory has both \"input\" and \"output\" directories.\n",
        "# 4 - Ensure the search directory contains the \"SearchWordsToExclude.rtf\" and \"TermsToSearch.rtf\" files.\n",
        "# 5 - Insert the epub, txt and PDF files to be searched.\n",
        "# 6 - Decide if you want to run automated, manual or semi-automated.\n",
        "# 7 - Run the program and your results will be contianed in the output directory.  Including converted PDF files, summary of terms/directory searched and results.\n",
        "# 8 - The only known acceptable abend is due to a PDF file that is simply a concatination of images with no text.  You will need to do an OCR before using this program.\n",
        "\n",
        "\n",
        "directoryvar = '/Users/freethebuddha/cloudstation/research'   #TODO BIG LOOP PROBLEM  must have a directory set in order to know where the DirectoryToSearch file exists\n",
        "\n",
        "\n",
        "                                                            \n",
        "\n",
        "chdir(directoryvar)\n",
        "searchdirectory = open(\"DirectoryToSearch.rtf\").read()         # TODO need to check if directories input and output exist\n",
        "\n",
        "\n",
        "directory=searchdirectory.split(\":\")[1]\n",
        "directoryvar=directory.split(\"}\")[0]\n",
        "\n",
        "####################################################################################\n",
        "###############################  PROCEDURES ########################################\n",
        "####################################################################################\n",
        "\n",
        "##############################  epub Conversion  ######################################\n",
        "#######   \n",
        "####### Input: \n",
        "#######     PDFfile: The PDF file to be converted\n",
        "#######\n",
        "####### Output:\n",
        "#######     A clear text file named 'data.txt' which will be used by the word search processes\n",
        "#######\n",
        "####### Internal variables etc.:\n",
        "#######     Several for the PDF conversion process\n",
        "#######         names are based on score counts (Low, Med, Hi)\n",
        "####### Global variables etc.:\n",
        "#######\n",
        "#######\n",
        "####### Purpose: Take the text where terms were found, these locations and  output\n",
        "#######         to the appropriate files(see file name structure)\n",
        "####################################################################################\n",
        "import urllib.request, urllib.parse, urllib.error\n",
        "import zipfile\n",
        "\n",
        "import xml.parsers.expat\n",
        "import html2text\n",
        "from glob import glob\n",
        "\n",
        "\n",
        "\n",
        "class ContainerParser():\n",
        "  def __init__(self,xmlcontent=None):\n",
        "    self.rootfile = \"\"  \n",
        "    self.xml = xmlcontent\n",
        "\n",
        "  def startElement(self, name, attributes):\n",
        "    if name == \"rootfile\": \n",
        "      self.buffer = \"\"    \n",
        "      self.rootfile = attributes[\"full-path\"]\n",
        "\n",
        "  def parseContainer(self):\n",
        "    parser = xml.parsers.expat.ParserCreate()\n",
        "    parser.StartElementHandler = self.startElement\n",
        "    parser.Parse(self.xml, 1)\n",
        "    return self.rootfile\n",
        "\n",
        "class BookParser():\n",
        "  def __init__(self,xmlcontent=None):\n",
        "    self.xml = xmlcontent \n",
        "    self.title = \"\" \n",
        "    self.author = \"\" \n",
        "    self.inTitle = 0\n",
        "    self.inAuthor = 0\n",
        "    self.ncx = \"\"\n",
        "\n",
        "  def startElement(self, name, attributes):\n",
        "    if name == \"dc:title\":\n",
        "      self.buffer = \"\"\n",
        "      self.inTitle = 1 \n",
        "    elif name == \"dc:creator\":\n",
        "      self.buffer = \"\"\n",
        "      self.inAuthor = 1 \n",
        "    elif name == \"item\":\n",
        "      if attributes[\"id\"] == \"ncx\" or attributes[\"id\"] == \"toc\" or attributes[\"id\"] == \"ncxtoc\":\n",
        "        self.ncx = attributes[\"href\"]\n",
        "\n",
        "  def characters(self, data):\n",
        "    if self.inTitle:\n",
        "      self.buffer += data\n",
        "    elif self.inAuthor:\n",
        "      self.buffer += data\n",
        "\n",
        "  def endElement(self, name):\n",
        "    if name == \"dc:title\":\n",
        "      self.inTitle = 0  \n",
        "      self.title = self.buffer  \n",
        "      self.buffer = \"\"\n",
        "    elif name == \"dc:creator\":\n",
        "      self.inAuthor = 0  \n",
        "      self.author = self.buffer  \n",
        "      self.buffer = \"\"\n",
        "\n",
        "  def parseBook(self):\n",
        "    parser = xml.parsers.expat.ParserCreate()\n",
        "    parser.StartElementHandler = self.startElement\n",
        "    parser.EndElementHandler = self.endElement\n",
        "    parser.CharacterDataHandler  = self.characters\n",
        "    parser.Parse(self.xml, 1)\n",
        "    return self.title,self.author, self.ncx\n",
        "\n",
        "class NavPoint():\n",
        "  def __init__(self,id=None,playorder=None,level=0,content=None,text=None):\n",
        "    self.id = id \n",
        "    self.content = content\n",
        "    self.playorder = playorder\n",
        "    self.level = level\n",
        "    self.text = text\n",
        "\n",
        "class TocParser():\n",
        "  def __init__(self,xmlcontent=None):\n",
        "    self.xml = xmlcontent \n",
        "    self.currentNP = None\n",
        "    self.stack = []\n",
        "    self.inText = 0\n",
        "    self.toc = []\n",
        "\n",
        "  def startElement(self, name, attributes):\n",
        "    if name == \"navPoint\":\n",
        "      level = len(self.stack)\n",
        "      self.currentNP = NavPoint(attributes[\"id\"], attributes[\"playOrder\"], level)\n",
        "      self.stack.append(self.currentNP)\n",
        "      self.toc.append(self.currentNP) \n",
        "    elif name == \"content\":\n",
        "      self.currentNP.content = urllib.parse.unquote(attributes[\"src\"])\n",
        "    elif name == \"text\":\n",
        "      self.buffer = \"\"\n",
        "      self.inText = 1\n",
        "\n",
        "  def characters(self, data):\n",
        "    if self.inText:\n",
        "      self.buffer += data\n",
        "\n",
        "  def endElement(self, name):\n",
        "    if name == \"navPoint\":\n",
        "      self.currentNP = self.stack.pop()\n",
        "    elif name == \"text\":\n",
        "      if self.inText and self.currentNP:\n",
        "        self.currentNP.text = self.buffer\n",
        "      self.inText = 0  \n",
        "\n",
        "  def parseToc(self):\n",
        "    parser = xml.parsers.expat.ParserCreate()\n",
        "    parser.StartElementHandler = self.startElement\n",
        "    parser.EndElementHandler = self.endElement\n",
        "    parser.CharacterDataHandler  = self.characters\n",
        "    parser.Parse(self.xml, 1)\n",
        "    return self.toc\n",
        "\n",
        "class epub2txt():\n",
        "  def __init__(self,epubfile=None):\n",
        "    self.epub = epubfile  \n",
        "    \n",
        "    \n",
        "\n",
        "  def convert(self):\n",
        "    epubtext = ' '\n",
        "    print(\"Processing %s ...\" % self.epub)\n",
        "    file = zipfile.ZipFile(self.epub,\"r\")\n",
        "    rootfile = ContainerParser(file.read(\"META-INF/container.xml\")).parseContainer()\n",
        "    title, author, ncx = BookParser(file.read(rootfile)).parseBook()\n",
        "    ops = \"/\".join(rootfile.split(\"/\")[:-1])\n",
        "    if ops != \"\":\n",
        "      ops = ops+\"/\"\n",
        "    toc = TocParser(file.read(ops + ncx)).parseToc()\n",
        "\n",
        "    #fo = open(\"%s_%s.txt\" % (title, author), \"w\")         commented out to prevent writing out file \n",
        "    for t in toc:\n",
        "      html = file.read(ops + t.content.split(\"#\")[0])\n",
        "      text = html2text.html2text(html.decode(\"utf-8\"))\n",
        "      epubtext = epubtext + text\n",
        "    \n",
        "      #fo.write(text + \"\\n\")\n",
        "    #fo.close()\n",
        "    file.close()\n",
        "    return(epubtext)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "##############################  String Chop  ######################################\n",
        "#######   \n",
        "####### Input: \n",
        "#######     PDFfile: The PDF file name to be chopped\n",
        "#######\n",
        "####### Output:\n",
        "#######     A clear text version of the file name minus the characters to be chopped at the end\n",
        "#######\n",
        "####### Internal variables etc.:\n",
        "#######     s - a variable containing the passed input string and returned chopped string\n",
        "#######     suffix - the string containing the passed input string of characters to chop off   \n",
        "#######\n",
        "####### Purpose: Input a string along with the characters to be chopped at the end of the string.\n",
        "#######         Chopped off the characters passed and return the chopped string\n",
        "####################################################################################\n",
        "def rchop(s, suffix):\n",
        "    if suffix and s.endswith(suffix):\n",
        "        return s[:-len(suffix)]\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "##############################  PDF Conversion  ######################################\n",
        "#######   \n",
        "####### Input: \n",
        "#######     PDFfile: The PDF file to be converted\n",
        "#######\n",
        "####### Output:\n",
        "#######     A clear text file named 'data.txt' which will be used by the word search processes\n",
        "#######\n",
        "####### Internal variables etc.:\n",
        "#######     Several for the PDF conversion process\n",
        "#######         names are based on score counts (Low, Med, Hi)\n",
        "#######\n",
        "####### Purpose: Take the text where terms were found, these locations and  output\n",
        "#######         to the appropriate files(see file name structure)\n",
        "####################################################################################\n",
        "\n",
        "\n",
        "\n",
        "def PDFConvert(PDFfile):\n",
        "    \n",
        "    from pdfminer3.layout import LAParams, LTTextBox\n",
        "    from pdfminer3.pdfpage import PDFPage\n",
        "    from pdfminer3.pdfinterp import PDFResourceManager\n",
        "    from pdfminer3.pdfinterp import PDFPageInterpreter\n",
        "    from pdfminer3.converter import PDFPageAggregator\n",
        "    from pdfminer3.converter import TextConverter\n",
        "    import io\n",
        "\n",
        "\n",
        "\n",
        "    chdir(directoryvar+directoryinput)\n",
        "    \n",
        "    print('Converting PDF')\n",
        "\n",
        "    resource_manager = PDFResourceManager()\n",
        "    fake_file_handle = io.StringIO()\n",
        "    converter = TextConverter(resource_manager, fake_file_handle, laparams=LAParams())\n",
        "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
        "\n",
        "    \n",
        "    with open(PDFfile, 'rb') as fh:\n",
        "\n",
        "        for page in PDFPage.get_pages(fh,\n",
        "                                    caching=True,\n",
        "                                    check_extractable=True):\n",
        "            page_interpreter.process_page(page)\n",
        "\n",
        "        text = fake_file_handle.getvalue()\n",
        "\n",
        "    # close open handles\n",
        "    converter.close()\n",
        "    fake_file_handle.close()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    chdir(directoryvar+directoryoutput) \n",
        "   \n",
        "    somestring = PDFfile\n",
        "    PDFfile = rchop(somestring, '.pdf')\n",
        "    \n",
        "    f = open(PDFfile+'.txt', 'w')   #TODO Fix this by removing .pdf extention and adding .txt\n",
        "    print(text, file=f)\n",
        "    \n",
        "    f.close()\n",
        "\n",
        "\n",
        "    return (text)  \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def ProcessTextFile(pdfdata,chunksize):\n",
        "###################### PROCESSING OF TEXT FILE ##############################\n",
        "#######   \n",
        "####### Input: \n",
        "#######     pdfdata: \n",
        "#######     \n",
        "#######\n",
        "####### Output:\n",
        "#######     text: \n",
        "#######\n",
        "####### Internal variables etc.:\n",
        "#######     ***.txt - \n",
        "####### Global variables etc.:\n",
        "#######     n      \n",
        "#######\n",
        "####### Purpose: \n",
        "#######         \n",
        "####################################################################################\n",
        "    \n",
        "\n",
        " \n",
        "  \n",
        "\n",
        "    chdir(directoryvar)\n",
        "\n",
        "    TotalScore = 0\n",
        "    i = 0           #Index\n",
        "    s = 0           #Index\n",
        "    z = 0           #Index\n",
        "    hits ={}\n",
        "    charpos = 0     # Initializing the character capturing loop to the first position\n",
        "    PDFtext ={}\n",
        "    SavedHits =[]\n",
        "    Score=0         # Score as accumulated during the file search\n",
        "\n",
        "\n",
        "    Fname = n       # from manual input of file name\n",
        "\n",
        "\n",
        "\n",
        "    print('chunksize: ',chunksize)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    maxchar=len(pdfdata)\n",
        "    finalpass=False\n",
        "    print('maxchar', maxchar)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    while charpos+chunksize < maxchar+1:\n",
        "        Score=0\n",
        "        Hit=1\n",
        "        DHit=2\n",
        "        \n",
        "        \n",
        "\n",
        "        chunk= pdfdata[charpos:charpos+chunksize]  #changed from achunk to pdfdata\n",
        "        \n",
        "        \n",
        "\n",
        "        #######  Search text inc score by 1 or 2\n",
        "        \n",
        "            #Search using 1 point SearchTerms\n",
        "        \n",
        "    \n",
        "        \n",
        "        for x in range(0,len(SearchTerms)):\n",
        "            if SearchTerms[x] in chunk:   # TODO ADD a copy of the SearchTerms list with counter added. Increment as found\n",
        "                Score+=Hit\n",
        "                \n",
        "    \n",
        "\n",
        "            #Search using 2 point SearchTerms   INCLUDES SCORE FROM SEARCHTERMS********************\n",
        "        for x in range(0,len(DSearchTerms)):\n",
        "            if DSearchTerms[x] in chunk: \n",
        "                Score+=DHit\n",
        "                \n",
        "                \n",
        "        if Score > 0:  \n",
        "            ###limiter = str('@')\n",
        "            ###SavedHits.append(limiter+Score+limiter)      # TODO look into putting an identifier after score number but having issue with str\n",
        "            SavedHits.append(Score)\n",
        "            SavedHits.append(charpos)\n",
        "            SavedHits.append(chunk)\n",
        "        \n",
        "\n",
        "        charpos=charpos+chunksize\n",
        "        if not finalpass:\n",
        "            if charpos+chunksize > maxchar: \n",
        "                chunksize=maxchar-charpos\n",
        "                finalpass=True\n",
        "        \n",
        "\n",
        "        TotalScore=TotalScore+Score \n",
        "    \n",
        "    HitsLow = {}\n",
        "    HitsMed = {}\n",
        "    HitsHi = {}\n",
        "    HLScore = 0\n",
        "    HMScore = 0\n",
        "    HHScore = 0\n",
        "\n",
        "    while z in range(0,len(SavedHits)):\n",
        "        \n",
        "        \n",
        "        if SavedHits[z] <ScoreValLow or SavedHits[z] is ScoreValLow: \n",
        "            HitsLow[SavedHits[z+1]] = str(SavedHits[z])+\"@\"+SavedHits[z+2]\n",
        "            HLScore = HLScore + SavedHits[z]\n",
        "            \n",
        "            \n",
        "        \n",
        "        if SavedHits[z] >ScoreValLow and SavedHits[z] < ScoreValHi: \n",
        "            HitsMed[SavedHits[z+1]] = str(SavedHits[z])+\"@\"+SavedHits[z+2]\n",
        "            HMScore = HMScore + SavedHits[z]\n",
        "            \n",
        "\n",
        "        if SavedHits[z] > ScoreValHi or SavedHits[z] is ScoreValHi: \n",
        "            HitsHi[SavedHits[z+1]] = str(SavedHits[z])+\"@\"+SavedHits[z+2]\n",
        "            HHScore = HHScore + SavedHits[z]\n",
        "            \n",
        "            \n",
        "        z+=3 ### Increment 3 (Score, CharacterPosition, Chunk)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return(HitsLow,HitsMed,HitsHi,HLScore,HMScore,HHScore,TotalScore,maxchar)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################  writingfiles  ######################################\n",
        "#######   \n",
        "####### Input: \n",
        "#######     Hits: Dictionary containing text and location where terms were found\n",
        "#######     filetype: String containing if Low Med or Hi should be used in file name\n",
        "#######\n",
        "####### Output:\n",
        "#######     Clear text files using naming convention below in Internal variables etc.\n",
        "#######\n",
        "####### Internal variables etc.:\n",
        "#######     Hits***.txt - output files with location and text where found. File\n",
        "#######         names are based on score counts (Low, Med, Hi)\n",
        "#######\n",
        "####### Purpose: Take the text where terms were found, these locations and  output\n",
        "#######         to the appropriate files(see file name structure)\n",
        "####################################################################################\n",
        "def writingfiles(Fname,Hits,filetype,typescore,maxchar):\n",
        "    \n",
        "    #directoryvar = '/Users/freethebuddha/cloudstation/Development/test'\n",
        "    #directoryoutput = '/output'\n",
        "\n",
        "    chdir(directoryvar+directoryoutput)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    print('I am writing files')\n",
        "    # current date and time\n",
        "    now = datetime.now()\n",
        "    timestamp = now.strftime(\"Date:%m-%d  Time:%H-%M\")\n",
        "    # dd/mm/YY H:M:S format\n",
        "    print(\"Timestamp:\", timestamp)\n",
        "\n",
        "    \n",
        "    with open(\"%s%s%s%s%s%s%d%s%d.txt\" %(Fname,'--', timestamp, '--', filetype, \" Score:\", typescore, '--',TotalScore), \"w\") as f:    \n",
        "        for key in Hits:\n",
        "            \n",
        "            \n",
        "            V=str(Hits[key])\n",
        "           \n",
        "            \n",
        "            \n",
        "            \n",
        "            f.write(\"\\n\\n\\n\")\n",
        "            f.write(\"%s%d%s%d%s%s%d\\n\"%('Location:',key,' of ',maxchar, '     ', 'Total Score:', TotalScore))\n",
        "            \n",
        "            for x in range(0,len(V)):\n",
        "                if V[x] is '@':\n",
        "                    scorelocation = x\n",
        "            \n",
        "            i=0\n",
        "            \n",
        "            f.write(\"The score of this chunk is \")\n",
        "            while i < scorelocation:\n",
        "                #i+=1    when looking for delimiter prior to score amount\n",
        "                f.write(V[i])\n",
        "                i+=1\n",
        "                \n",
        "            #chdir(\"/Users/freethebuddha/cloudstation/Development/Test/Output\")   #TODO remove since the directory is not changed from initialization of this proc \n",
        "            f.write(\"\\n\\n\\n\")\n",
        "            f.write(\"%s\\n\\n\"%'**************************************************')\n",
        "            \n",
        "            \n",
        "            f.write(\"%s\\n\"%V)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "#######  Getting words from file to use in \"getSearchWords\"  function ###########\n",
        "def getWords(text):\n",
        "    return re.compile(r'\\w+').findall(text)\n",
        "\n",
        "\n",
        "\n",
        "##############################  getSearchWords  #####################################\n",
        "#######  Grab Search Terms ######## Search text in file must begin w/word \"SEARCH\"\n",
        "####### Input: \n",
        "#######     STerms: String containing search terms or the value 'n'\n",
        "#######    \n",
        "####### Output:\n",
        "#######     Two lists: SWords and DSWords\n",
        "#######\n",
        "####### Internal variables etc.:\n",
        "#######     SWords - List of search terms containing single point terms\n",
        "#######     DSWords - list of search terms containing double point terms\n",
        "#######\n",
        "####### Purpose: Passed a string.  If the first character is 'n' then the search\n",
        "#######     terms will be contained in the file \"TermsToSearch.rtf\".  Otherwise, the \n",
        "#######     terms are are in the list passed.  Parse the list to create a individual\n",
        "#######     lists of single point search words and double point search words.\n",
        "#######     -- Terms less than 2 characters are removed\n",
        "#######     -- Connector words are removed\n",
        "#######     -- Duplicate Terms are removed\n",
        "#######     -- Terms greater than 4 characters or are capitalized are put in the \n",
        "#######         double point list\n",
        "#######     -- Terms that are 3 and 4 characters and are not capitalized are placed\n",
        "#######         single point list\n",
        "####################################################################################\n",
        "def getSearchWords(STerms):\n",
        "\n",
        "    \n",
        "\n",
        "    chdir(directoryvar)\n",
        "   \n",
        "    \n",
        "    SWords = []\n",
        "    DSWords = []\n",
        "    ConnectorWords = []\n",
        "    \n",
        "    \n",
        "    if STerms[0] is 'n':\n",
        "    \n",
        "        searchfile = open(\"TermsToSearch.rtf\").read()\n",
        "        searchwords = getWords(searchfile)\n",
        "        \n",
        "    # Identify the loaction of the word Search which deliniates where terms start\n",
        "        location=searchwords.index('Search')\n",
        "\n",
        "    # Grab search terms from text file after the word Search\n",
        "        for i in range(location+1, len(searchwords)): \n",
        "            SWords.insert(i,searchwords[i])\n",
        "    else:\n",
        "        SWords=STerms\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    # Places terms with more than 4 characters into the DoubleSWords(DSWords)\n",
        "    #TODO should I move this to after the removal of all of the duplicates???\n",
        "    for element in SWords:\n",
        "        if len(element) > 4: DSWords.append(element)\n",
        "        #TODO should I then remove it from the SWords list????\n",
        "\n",
        "\n",
        "    # Removes terms less than 3 characters                                   #changed from 2 to 3 5-19-20\n",
        "    for element in SWords:\n",
        "        if len(element) <3: SWords.remove(element)\n",
        "\n",
        "    # Removes Duplicates\n",
        "    mylist = SWords\n",
        "    SWords = list(dict.fromkeys(mylist)) \n",
        "\n",
        "\n",
        "    # Removes connector words - ConnectorWords are contained in the file below:\n",
        "\n",
        "    ConnectorWordFile = open('SearchWordsToExclude.rtf').read()\n",
        "    CWords = getWords(ConnectorWordFile)\n",
        "    location=CWords.index('Exclude')\n",
        "        # Grab search terms from text file after the word Search\n",
        "    for i in range(location+1, len(CWords)): \n",
        "        ConnectorWords.insert(i,CWords[i])\n",
        "   \n",
        "\n",
        "    for element in SWords:\n",
        "        if element in ConnectorWords: SWords.remove(element)\n",
        "\n",
        "    # Removes terms less than 4 characters unless the are capitalize\n",
        "    #TODO does this have duplicate effort to the removal above???\n",
        "    for element in SWords:  \n",
        "        \n",
        "        if len(element) >1 and len(element) <4:\n",
        "            \n",
        "            if not re.findall('([A-Z]+)', element): \n",
        "                SWords.remove(element)\n",
        "            \n",
        "    \n",
        "    # Captures capitalized terms with length of 3 or 4 chars and copies them to Double\n",
        "    for element in SWords:\n",
        "        \n",
        "        if len(element) is 4 or len(element) is 3:\n",
        "            \n",
        "            \n",
        "            if not re.findall('([A-Z]+)', element): \n",
        "                print()\n",
        "                \n",
        "            else: \n",
        "                DSWords.append(element)\n",
        "                \n",
        "                \n",
        "\n",
        "    # Compares Double and if term in Search remove it from Search\n",
        "    for element in DSWords:\n",
        "       \n",
        "        if element in SWords: SWords.remove(element)\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    chdir(directoryvar+directoryoutput)\n",
        "    \n",
        "    Allsearchterms = []\n",
        "    now = datetime.now()\n",
        "    timestamp = now.strftime(\"%m-%d - %H-%M\")\n",
        "    with open(\"%s%s.txt\" %('Search and Excluded Terms --', timestamp), \"w\") as f:   \n",
        "\n",
        "        \n",
        "\n",
        "        f.write(\"%s%s%s\\n\\n%s%s\\n\\n%s%s\\n\"%('Search Terms: ', SWords,DSWords, 'Excluded Connector Terms:', ConnectorWords, 'Directory: ', directoryvar))\n",
        "\n",
        "         \n",
        "    f.close()\n",
        "\n",
        "\n",
        "\n",
        "    return (SWords,DSWords)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################################################################################\n",
        "##############################   MAINLINE  #########################################\n",
        "####################################################################################\n",
        "####### \n",
        "#######   STUB for requesting pdf file name to be search, file of what to be searched\n",
        "#######   and the size of the chunking  \n",
        "#######   Duplicate hits are not identified and therefore not counted\n",
        "#######   Singles, Doubles score correctly.   \n",
        "####### \n",
        "####################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################################################################################\n",
        "################################# INITIALIZATION ###################################\n",
        "####################################################################################\n",
        "\n",
        "\n",
        "TotalScore = 0  # Not currently being used\n",
        "PDFtext ={}\n",
        "SavedHits =[]\n",
        "x = []          # Search phrase that is manually entered\n",
        "pfile ='pdf'\n",
        "efile ='epub'\n",
        "tfile ='txt'\n",
        "rfile ='rtf'\n",
        "\n",
        "HitsL = {}\n",
        "HitsM = {}\n",
        "HitsH = {}\n",
        "\n",
        "HLScore = 0\n",
        "HMScore = 0\n",
        "HHScore = 0\n",
        "\n",
        "maxchar = 0\n",
        "\n",
        "n = 'n'\n",
        "\n",
        "ScoreValLow=2   # Low valued hits\n",
        "ScoreValMed=4   # Not used right now\n",
        "ScoreValHi=6 \n",
        "\n",
        "chunksizedefault = int(800)\n",
        "\n",
        "\n",
        "searchdirectory = open(\"DirectoryToSearch.rtf\").read()\n",
        "\n",
        "\n",
        "directory=searchdirectory.split(\":\")[1]\n",
        "directoryvar=directory.split(\"}\")[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#TODO fix this with DirectoryToSearch file input\n",
        "directoryinput = '/input'\n",
        "directoryoutput = '/output'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################## RETRIEVE SEARCH TERMS ####################################\n",
        "\n",
        "print('   Crawford Technologies Presents:  ')\n",
        "print()\n",
        "print('                                                PPPPPP     DDDD      FFFFFFF         ')\n",
        "print('                                               P     P    D  DD     F  ')\n",
        "print('                                              P     P    D    D    F')\n",
        "print('                                             PPPPPP     D    D    FFFFF           ')\n",
        "print('                                            P          D    D    F')\n",
        "print('                                           P          D  DD     F')\n",
        "print('                                          P          DDDD      F            ')\n",
        "print('                      ')\n",
        "print('                                 SSSSSS   EEEEEE       A       RRRRRR    CCCCCC   H    H')\n",
        "print('                                S        E           A A      R    R    C        H    H')\n",
        "print('                               SSSSSS   EEEEE      A   A     RRRRRR    C        HHHHHH')\n",
        "print('                                   S   E         A AAA A    R  R      C        H    H')\n",
        "print('                             SSSSSS   EEEEEE   A       A   R    R    CCCCCC   H    H')\n",
        "print('                                           ')\n",
        "print()\n",
        "print('   with TECHNOLOGIES from Buddhahacker!')\n",
        "print()\n",
        "\n",
        "#from datetime import datetime  \n",
        "\n",
        "# current date and time\n",
        "now = datetime.now()\n",
        "s2 = now.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
        "# dd/mm/YY H:M:S format\n",
        "print(\"s2:\", s2)\n",
        "\n",
        "\n",
        "\n",
        "auto=input(\"Enter 'A' if you like to go AUTO on this?\")\n",
        "\n",
        "if auto != 'A':\n",
        "\n",
        "    helpdefinitions = input(\"Enter 'Y' if you would like to see the default options?\")\n",
        "\n",
        "    if helpdefinitions is 'Y':\n",
        "        print('# of chars searched in a chunk: ',chunksizedefault)\n",
        "        print('The Low, Medium and High score values are: ', ScoreValLow, ScoreValMed, ScoreValHi)\n",
        "\n",
        "    n=input(\"Enter file name to be searched WITH OUT extension or 'n' to to source names from directory (batch mode: \")\n",
        "\n",
        "    if n != 'n':\n",
        "        e=input(\"Enter 'e' 't' 'p' if source search material is txt or PDF format: \")      # TODO Remove and search for file type\n",
        "\n",
        "    x=input(\"Enter phrase or terms to search in the PDF or enter 'n' to use the file: \")\n",
        "\n",
        "\n",
        "    chunksizeINPUT=int(input(\"Enter the amount of text you would like scanned at a time or '0' for default(chunksizedefault): \"))\n",
        "                                                                                        # TODO Need to add logic around pdf file name\n",
        "\n",
        "else:\n",
        "    x = 'n'\n",
        "    chunksizeINPUT=chunksizedefault\n",
        "\n",
        "    \n",
        "if x[0] is 'n':\n",
        "    STerms = 'n'\n",
        "else:\n",
        "    STerms = x.split()\n",
        "\n",
        "(SearchTerms,DSearchTerms) = getSearchWords(STerms)\n",
        "\n",
        "\n",
        "\n",
        "if chunksizeINPUT is 0:\n",
        "    chunksize=chunksizedefault \n",
        "else:\n",
        "    chunksize=int(chunksizeINPUT)               #### CHUNK SIZE ****\n",
        "\n",
        "if n != 'n':\n",
        "    #fileN = n\n",
        "    \n",
        "    if e is 'p':\n",
        "    \n",
        "        PDFfilenametoconvert = n+'.pdf'                                         # TODO Need to redo the entire prompting for file type. Not neccessary?\n",
        "        PDFtext=PDFConvert(PDFfilenametoconvert)                                            # TODO fix for passing data between procs rather than using files. See below:\n",
        "        (HitsL,HitsM,HitsH,HLScore,HMScore,HHScore,TotalScore,maxchar) = ProcessTextFile(PDFtext,chunksize)\n",
        "        ####################  Writing Output to Files   #####################\n",
        "        \n",
        "        writingfiles(PDFfilenametoconvert,HitsL,'L',HLScore,maxchar)\n",
        "        writingfiles(PDFfilenametoconvert,HitsM,'M',HMScore,maxchar)\n",
        "        writingfiles(PDFfilenametoconvert,HitsH,'H',HHScore,maxchar)\n",
        "\n",
        "    if e is 't':\n",
        "\n",
        "        filename = n+'.txt'\n",
        "        f=open(filename, \"r\")                                \n",
        "        if f.mode == 'r':\n",
        "            PDF_Text =f.read()                                 \n",
        "\n",
        "                             \n",
        "        print('txt converted')\n",
        "        print('chunk size: ',chunksize)\n",
        "        chdir(directoryvar)\n",
        "        (HitsL,HitsM,HitsH,HLScore,HMScore,HHScore,TotalScore,maxchar) = ProcessTextFile(PDF_Text,chunksize) \n",
        "       \n",
        "       \n",
        "        (HitsL,HitsM,HitsH,HLScore,HMScore,HHScore,TotalScore,maxchar) = ProcessTextFile(PDF_Text,chunksize)\n",
        "        ####################  Writing Output to Files   #####################\n",
        "        writingfiles(filename,HitsL,'L',HLScore,maxchar)\n",
        "        writingfiles(filename,HitsM,'M',HMScore,maxchar)\n",
        "        writingfiles(filename,HitsH,'H',HHScore,maxchar)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    # TODO make this as part of the else above\n",
        "\n",
        "if n is 'n':\n",
        "\n",
        "\n",
        "    chdir(directoryvar+directoryinput)\n",
        "    \n",
        "    print('enter mailine')\n",
        "    g=0\n",
        "    worker_count = 8\n",
        "    worker_pool = []\n",
        "    PDF_Text = {}\n",
        "    \n",
        "\n",
        "    arr = os.listdir('.')\n",
        "    print('Processing ', len(arr), 'files.')\n",
        "    print(arr)\n",
        "\n",
        "\n",
        "    while g in range (0,len(arr)):\n",
        "        fileentry = arr[g]\n",
        "        print('filename: ', fileentry)\n",
        "        HLScore = 0\n",
        "        HMScore = 0\n",
        "        HHScore = 0\n",
        "        print('Processing file ', g+1, 'of ', len(arr))\n",
        "        \n",
        "        if '.pdf' in fileentry:                                                 # added '.' in order to get only file\n",
        "            PDFfilenametoconvert = arr[g]\n",
        "            PDF_Text = PDFConvert(PDFfilenametoconvert)                         # convert pdf to text\n",
        "            print('pdf converted')\n",
        "            \n",
        "            chdir(directoryvar)\n",
        "            (HitsL,HitsM,HitsH,HLScore,HMScore,HHScore,TotalScore,maxchar) = ProcessTextFile(PDF_Text,chunksize)             # search text file\n",
        "        \n",
        "        \n",
        "            writingfiles(fileentry,HitsL,'L',HLScore,maxchar)                                       # write out results\n",
        "            writingfiles(fileentry,HitsM,'M',HMScore,maxchar)\n",
        "            writingfiles(fileentry,HitsH,'H',HHScore,maxchar)\n",
        "        \n",
        "        \n",
        "        else:\n",
        "            print('not pdf')\n",
        "        \n",
        "        if 'txt' in fileentry:                                                      \n",
        "            chdir(directoryvar+directoryinput)\n",
        "            filename = fileentry\n",
        "            f=open(filename, \"r\")\n",
        "\n",
        "                                                    \n",
        "            if f.mode == 'r':\n",
        "                book =f.read()                                 \n",
        "\n",
        "            PDF_Text = book                         \n",
        "            print('txt converted')\n",
        "            print('chunk size: ',chunksize)\n",
        "            chdir(directoryvar)\n",
        "            (HitsL,HitsM,HitsH,HLScore,HMScore,HHScore,TotalScore,maxchar) = ProcessTextFile(PDF_Text,chunksize)              # search text file\n",
        "        \n",
        "        \n",
        "            writingfiles(fileentry,HitsL,'L',HLScore,maxchar)                                       # write out results\n",
        "            writingfiles(fileentry,HitsM,'M',HMScore,maxchar)\n",
        "            writingfiles(fileentry,HitsH,'H',HHScore,maxchar)\n",
        "\n",
        "        else:\n",
        "            print('not text')\n",
        "        \n",
        "\n",
        "        if 'epub' in fileentry: \n",
        "            chdir(directoryvar+directoryinput)\n",
        "            epubfilenametoconvert = arr[g] \n",
        "            epubtext = epub2txt(epubfilenametoconvert).convert() \n",
        "            print('epub converted') \n",
        " \n",
        "            chdir(directoryvar) \n",
        "            (HitsL,HitsM,HitsH,HLScore,HMScore,HHScore,TotalScore,maxchar) = ProcessTextFile(epubtext,chunksize)  \n",
        "\n",
        "            writingfiles(fileentry,HitsL,'L',HLScore,maxchar)                                       # write out results \n",
        "            writingfiles(fileentry,HitsM,'M',HMScore,maxchar) \n",
        "            writingfiles(fileentry,HitsH,'H',HHScore,maxchar) \n",
        "        \n",
        "        else:\n",
        "            print('not epub')\n",
        "\n",
        "\n",
        "\n",
        "        g+=1\n",
        "    \n",
        "    \n",
        "    \n",
        "    n = \"stop\"\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-68e0e80b637d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectoryvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0msearchdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DirectoryToSearch.rtf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# TODO need to check if directories input and output exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/freethebuddha/cloudstation/research'"
          ]
        }
      ]
    }
  ]
}